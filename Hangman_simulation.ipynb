{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOOutyCaqr5oW9Jwv5WCIt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/branndonm1/branndonm1/blob/main/Hangman_simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MaskedWordDataset(Dataset):\n",
        "    def __init__(self, word_list, mask_prob=0.3):\n",
        "        self.words = word_list\n",
        "        self.vocab = sorted(list(set(\"\".join(self.words))))\n",
        "        self.char2idx = {c: i+1 for i, c in enumerate(self.vocab)}  # 0 for padding\n",
        "        self.char2idx['_'] = len(self.char2idx) + 1  # Special token for blank\n",
        "        self.idx2char = {i: c for c, i in self.char2idx.items()}\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_len = max(len(w) for w in self.words)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        word = self.words[idx]\n",
        "        masked = []\n",
        "        target = []\n",
        "        for c in word:\n",
        "            if random.random() < self.mask_prob:\n",
        "                masked.append('_')\n",
        "                target.append(c)\n",
        "            else:\n",
        "                masked.append(c)\n",
        "                target.append(None)\n",
        "\n",
        "        input_ids = [self.char2idx.get(c, 0) for c in masked]\n",
        "        target_ids = [self.char2idx[c] if c else 0 for c in target]\n",
        "        mask = [1 if t else 0 for t in target]\n",
        "\n",
        "        # Pad\n",
        "        while len(input_ids) < self.max_len:\n",
        "            input_ids.append(0)\n",
        "            target_ids.append(0)\n",
        "            mask.append(0)\n",
        "\n",
        "        return torch.tensor(input_ids), torch.tensor(target_ids), torch.tensor(mask)\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class MaskedCharModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=64, hidden_dim=128):\n",
        "        super(MaskedCharModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 2, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.classifier = nn.Linear(hidden_dim * 2, vocab_size + 1)  # Not including '_' or padding\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(emb)\n",
        "        logits = self.classifier(lstm_out)  # (batch, seq_len, vocab_size)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x, y, mask in dataloader:\n",
        "        x, y, mask = x.to(device), y.to(device), mask.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(x)  # (B, L, V)\n",
        "        logits = logits.view(-1, logits.size(-1))\n",
        "        y = y.view(-1)\n",
        "        mask = mask.view(-1)\n",
        "\n",
        "        loss = criterion(logits[mask == 1], y[mask == 1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def predict_blanks(model, input_str, char2idx, idx2char, device, max_len=20):\n",
        "    model.eval()\n",
        "    input_ids = [char2idx.get(c, 0) for c in input_str]\n",
        "    input_ids += [0] * (max_len - len(input_ids))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor([input_ids]).to(device)\n",
        "        logits = model(input_tensor)[0]  # shape: (seq_len, vocab_size)\n",
        "\n",
        "        # Build a set of visible letters in the input\n",
        "        visible_letters = set(c for c in input_str if c != '_' and c in char2idx)\n",
        "\n",
        "        # Convert visible letters to indices\n",
        "        forbidden_indices = [char2idx[c] for c in visible_letters]\n",
        "\n",
        "        # Mask out forbidden letters by setting logits to -inf\n",
        "        for i, c in enumerate(input_str):\n",
        "            if c == '_':\n",
        "                logits[i][forbidden_indices] = float('-inf')  # Prevent reused characters\n",
        "\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    result = {}\n",
        "    for i, c in enumerate(input_str):\n",
        "        if c == '_':\n",
        "            for j in range(1, len(idx2char)):\n",
        "                ch = idx2char[j]\n",
        "                prob = probs[i][j].item()\n",
        "                if prob > 0:\n",
        "                    result[ch] = result.get(ch, 0) + prob\n",
        "\n",
        "    total = sum(result.values())\n",
        "    if total == 0:\n",
        "        return []\n",
        "    result = [(ch, p / total) for ch, p in sorted(result.items(), key=lambda x: -x[1])]\n",
        "    return result\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# Load your 250K word list\n",
        "with open(\"words_250000_train.txt\") as f:\n",
        "  word_list = [line.strip().lower() for line in f if line.strip().isalpha()]\n",
        "\n",
        "\n",
        "dataset = MaskedWordDataset(word_list)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = MaskedCharModel(vocab_size=len(dataset.char2idx)).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    loss = train(model, dataloader, optimizer, criterion, device)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26jbYx7yK4Zf",
        "outputId": "e44bf08b-1752-4c5a-dddf-dd99c0eeb3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 2.1929\n",
            "Epoch 2: Loss = 2.0172\n",
            "Epoch 3: Loss = 1.9607\n",
            "Epoch 4: Loss = 1.9317\n",
            "Epoch 5: Loss = 1.9128\n",
            "Epoch 6: Loss = 1.8956\n",
            "Epoch 7: Loss = 1.8822\n",
            "Epoch 8: Loss = 1.8703\n",
            "Epoch 9: Loss = 1.8612\n",
            "Epoch 10: Loss = 1.8580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = \"te__er\"\n",
        "result = predict_blanks(model, input_str, dataset.char2idx, dataset.idx2char, device)\n",
        "print(result)  # [('e', 0.23), ('o', 0.18), ...]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SckEyvTlLKpQ",
        "outputId": "ea0f940c-7fc7-44bc-91cd-89999583e592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('n', 0.19607991624719115), ('l', 0.1852843710593658), ('k', 0.12297534124521213), ('s', 0.08546447848587933), ('d', 0.055260395119455005), ('a', 0.047677083926141665), ('z', 0.04291503668275719), ('p', 0.04094336223339335), ('m', 0.03568729037386653), ('i', 0.03283926021226334), ('g', 0.027158040980432615), ('h', 0.025884854876116716), ('c', 0.020566631784606458), ('w', 0.017789772830833696), ('v', 0.014827331404303964), ('u', 0.013889362560820176), ('b', 0.012228238827427605), ('f', 0.012087789063027396), ('o', 0.004583039529870631), ('x', 0.0034127418142365605), ('y', 0.0023263112271546663), ('j', 7.607764450745664e-05), ('q', 4.327187113656015e-05)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hangman_simulator(target_word, guess_fn, max_attempts=6, verbose=True):\n",
        "    guessed_letters = set()\n",
        "    attempts_left = max_attempts\n",
        "    current_masked = ['_' for _ in target_word]\n",
        "\n",
        "    def update_mask(letter):\n",
        "        return [letter if target_word[i] == letter else current_masked[i]\n",
        "                for i in range(len(target_word))]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Target word: {'_' * len(target_word)} (hidden)\")\n",
        "    while attempts_left > 0 and '_' in current_masked:\n",
        "        guess = guess_fn(\"\".join(current_masked), guessed_letters)\n",
        "        guessed_letters.add(guess)\n",
        "\n",
        "        if guess in target_word:\n",
        "            current_masked = update_mask(guess)\n",
        "            if verbose:\n",
        "                print(f\"âœ… Correct guess: {guess} â†’ {''.join(current_masked)}\")\n",
        "        else:\n",
        "            attempts_left -= 1\n",
        "            if verbose:\n",
        "                print(f\"âŒ Wrong guess: {guess} â†’ {''.join(current_masked)} | Lives left: {attempts_left}\")\n",
        "\n",
        "    if '_' not in current_masked:\n",
        "        if verbose:\n",
        "            print(f\"ðŸŽ‰ You won! Word was: {target_word}\")\n",
        "        return True\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"ðŸ’€ You lost. Word was: {target_word}\")\n",
        "        return False\n",
        "\n",
        "used_guesses = set()\n",
        "\n",
        "def guess(masked_word, guessed_letters):\n",
        "    global used_guesses\n",
        "\n",
        "    #if not used_guesses:\n",
        "    #    used_guesses.add('e')\n",
        "    #    return 'e'\n",
        "\n",
        "\n",
        "\n",
        "    # Get model probabilities\n",
        "    result = predict_blanks(model, masked_word, dataset.char2idx, dataset.idx2char, device, max_len=dataset.max_len)\n",
        "\n",
        "    # Guess the highest ranked character not already guessed\n",
        "    for char, _ in result:\n",
        "        if char not in guessed_letters:\n",
        "            used_guesses.add(char)\n",
        "            return char\n",
        "\n",
        "    # fallback\n",
        "    for c in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        if c not in guessed_letters:\n",
        "            used_guesses.add(c)\n",
        "            return c\n",
        "\n",
        "    return 'a'  # Default fallback\n",
        "\n",
        "used_guesses = set()\n",
        "\n",
        "hangman_simulator(\"principal\", guess_fn=guess)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvdGWPvVOe1R",
        "outputId": "95e9894b-fdff-4b7f-b4ae-3af1361f3c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target word: _________ (hidden)\n",
            "âŒ Wrong guess: e â†’ _________ | Lives left: 5\n",
            "âŒ Wrong guess: s â†’ _________ | Lives left: 4\n",
            "âœ… Correct guess: i â†’ __i__i___\n",
            "âœ… Correct guess: n â†’ __in_i___\n",
            "âŒ Wrong guess: t â†’ __in_i___ | Lives left: 3\n",
            "âœ… Correct guess: a â†’ __in_i_a_\n",
            "âœ… Correct guess: c â†’ __inci_a_\n",
            "âœ… Correct guess: l â†’ __inci_al\n",
            "âœ… Correct guess: r â†’ _rinci_al\n",
            "âœ… Correct guess: p â†’ principal\n",
            "ðŸŽ‰ You won! Word was: principal\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_hangman_simulation(model, dataset, word_list_1000, num_games=1000, verbose_every=0):\n",
        "    wins = 0\n",
        "    total = 0\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    def predict_blanks_for_game(masked_word, guessed_letters):\n",
        "        result = predict_blanks(model, masked_word, dataset.char2idx, dataset.idx2char, device, max_len=dataset.max_len)\n",
        "        for char, _ in result:\n",
        "            if char not in guessed_letters:\n",
        "                return char\n",
        "        for c in 'abcdefghijklmnopqrstuvwxyz':\n",
        "            if c not in guessed_letters:\n",
        "                return c\n",
        "        return 'a'\n",
        "\n",
        "    for i in range(num_games):\n",
        "        target_word = random.choice(word_list_1000)\n",
        "        used_guesses.clear()  # Reset per game\n",
        "\n",
        "        def guess(masked_word, guessed_letters):\n",
        "            global used_guesses\n",
        "            return predict_blanks_for_game(masked_word, guessed_letters)\n",
        "\n",
        "        win = hangman_simulator(target_word, guess_fn=guess, max_attempts=6, verbose=(verbose_every > 0 and i % verbose_every == 0))\n",
        "        wins += int(win)\n",
        "        total += 1\n",
        "\n",
        "    win_rate = wins / total\n",
        "    print(f\"\\nâœ… Hangman Strategy Win Rate: {wins}/{total} = {win_rate:.2%}\")\n",
        "    return win_rate\n",
        "\n",
        "\n",
        "# Make sure this is your 1000-word test list\n",
        "word_list_1000 = random.sample(dataset.words, 1000)\n",
        "\n",
        "# Run simulation\n",
        "run_hangman_simulation(model, dataset, word_list_1000, num_games=1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6RISjRdPhXu",
        "outputId": "52a55e45-4750-491a-f353-48874791e14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Hangman Strategy Win Rate: 504/1000 = 50.40%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.504"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "from nltk.corpus import words\n",
        "\n",
        "all_words = [w.lower() for w in words.words() if w.isalpha() and len(w) >= 4]\n",
        "word_list_external = random.sample(all_words, 1000)  # or fewer if you want\n",
        "\n",
        "\n",
        "# Filter to only words fully covered by model vocab\n",
        "#def filter_words_by_vocab(word_list, allowed_chars):\n",
        "#    return [w for w in word_list if all(c in allowed_chars for c in w)]\n",
        "\n",
        "#allowed_chars = set(dataset.char2idx.keys())\n",
        "#word_list_external = filter_words_by_vocab(word_list_external, allowed_chars)\n",
        "\n",
        "# Now simulate\n",
        "run_hangman_simulation(model, dataset, word_list_external, num_games=1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPFGSEoqSJw0",
        "outputId": "5f23c7bf-e95a-4d20-f437-81fcde30476b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Hangman Strategy Win Rate: 553/1000 = 55.30%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.553"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model and metadata\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'char2idx': dataset.char2idx,\n",
        "    'idx2char': dataset.idx2char\n",
        "}, 'masked_char_model.pth')\n"
      ],
      "metadata": {
        "id": "iYaSADTRzA5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load checkpoint\n",
        "checkpoint = torch.load('masked_char_model.pth', map_location=device)\n",
        "\n",
        "# Recreate dataset-dependent variables\n",
        "char2idx = checkpoint['char2idx']\n",
        "idx2char = checkpoint['idx2char']\n",
        "vocab_size = len(char2idx)\n",
        "\n",
        "# Recreate model\n",
        "model = MaskedCharModel(vocab_size=vocab_size).to(device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "84haNTQOzHtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZsz6FdbftHs",
        "outputId": "b9246b41-0c72-4b6f-dc1e-f3d723fb4816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_pp_e\n"
          ]
        }
      ]
    }
  ]
}